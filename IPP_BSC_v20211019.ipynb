{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IPP BSC v20211019.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orlandokohjy/IPP-BSC/blob/main/IPP_BSC_v20211019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "# Recovery script\n",
        "Due to broken laptop, this is the only latest script I have for this project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "user_directory = '/Users/jiayikoh/Downloads/OneDrive_1_16-06-2021/'\n",
        "insurance_file = 'Compliance BSC.xlsx'\n",
        "investment_file = 'Jan - Mar 2020 CIS Report.xlsx'\n",
        "product_file = 'Approved product and Bundled Poduct List 21 Jan 2020.xlsx'\n",
        "\n",
        "#oldadvisor_file = input('File name of the Old Advisor information (including the format -> oldadvcheck.xlsx)')\n",
        "    \n",
        "os.chdir(user_directory)\n",
        "compliance = pd.read_excel(insurance_file,header=[0]) \n",
        "compliance = pd.DataFrame(compliance)\n",
        "cis = pd.read_excel(investment_file,header=[0]) \n",
        "cis = pd.DataFrame(cis)\n",
        "pro = pd.read_excel(product_file, sheet_name = 'IPPFA App', header = [7])\n",
        "\n",
        "##to manage insurance data\n",
        "#Remove any data that contain blank in 'Advisor'\n",
        "compliance.dropna(subset=['Advisor'], inplace = True)\n",
        "\n",
        "#Remove duplicates except for two fields\n",
        "compliance = compliance.drop_duplicates(subset=compliance.columns.difference(['Modified On','Case Modified On']),keep='first')\n",
        "\n",
        "#Fill null values with blank string for data manipulation purpose\n",
        "compliance[compliance['Plan Type'] == 'Term Life'][['Subject To BSC']].fillna('Yes',inplace=True)\n",
        "compliance[['Accredited Investor','Subject To BSC']] = compliance[['Accredited Investor','Subject To BSC']].fillna('')\n",
        "\n",
        "\n",
        "#create 'BSC' column and remove whitespace for all names columns in order to find whether is FAR own trade policy\n",
        "compliance['Compliance BSC (Y/N)'] = ''\n",
        "\n",
        "farreq1 = compliance['Subject To BSC'] == 'No (No Advice)'\n",
        "farreq2 = compliance['Subject To BSC'] == 'Yes'\n",
        "\n",
        "compliance['name_check_1'] = compliance.loc[:,'Advisor'].str.lower().str.strip().str.replace(' ','')\n",
        "\n",
        "compliance['name_check_2'] = compliance.loc[:,'Contact Name'].str.lower().str.strip().str.replace(' ','')\n",
        "\n",
        "compliance['name_check_3'] = compliance.loc[:,'All Advisors'].str.lower().str.strip().str.replace(' ','')\n",
        "\n",
        "#to identify FAR own trade policy using name\n",
        "def check_name(row):\n",
        "    return row['name_check_1'] in row['name_check_2'] or row['name_check_1'] in row['name_check_3'] or row['name_check_2'] in row['name_check_1'] or row['name_check_2'] in row['name_check_3'] or row['name_check_3'] in row['name_check_1'] or row['name_check_3'] in row['name_check_2']\n",
        "\n",
        "compliance.loc[compliance.apply(check_name, axis = 1),('Compliance BSC (Y/N)')] = 'Yes (FAR own trade)'\n",
        "\n",
        "\n",
        "#to identify FAR own trade policy using client's email address\n",
        "compliance.loc[compliance['All E-mail Addresses.1'].notna() & compliance['All E-mail Addresses.1'].str.contains('ippfa.com'),'Compliance BSC (Y/N)'] = \"Yes (FAR own trade)\"\n",
        "\n",
        "#open the 'IPPFA approved list' for 'Term Life' insurance plan\n",
        "pro = pro.reindex(['Plan Type', 'Product Classification', 'Type', 'Carrier', 'Plan Name',\n",
        "       'LPHR / Approved'], axis = 'columns', fill_value = '')\n",
        "pro.dropna(axis = 0, inplace = True)\n",
        "\n",
        "#merge both files for easy data manipulation (to check whether there is wrong labelling for 'Term Life')\n",
        "compliance = pd.merge(compliance, pro, how = 'left', on = 'Plan Name')\n",
        "\n",
        "#to check against the IPPFA Approved list\n",
        "compliance.rename(columns = {'Plan Type_x':'Plan Type'}, inplace = True)\n",
        "compliance['Type'].replace(np.NaN, '', inplace = True)\n",
        "compliance['Plan Type'].replace(np.NaN, '', inplace = True)\n",
        "check_1 = compliance['Type'].str.contains('Term Life')\n",
        "#check_2 = compliance['Plan Type_x'] != compliance['Type']\n",
        "compliance.loc[check_1, 'Plan Type'] = compliance['Type']\n",
        "compliance.loc[compliance['Plan Type'] == '', 'Plan Type'] = compliance['Type']\n",
        "\n",
        "#for term life, when can't find plan in the approved list then \"No\"\n",
        "#hi_1 = compliance['Plan Type'] == 'Term Life'\n",
        "#hi_2 = compliance['Type'] == ''\n",
        "#compliance.loc[hi_1 & hi_2, 'Compliance BSC (Y/N)'] = 'No'\n",
        "\n",
        "#for term life, wrong labelling for 'Plan Type' in the compliance file\n",
        "hi_1 = compliance['Plan Type'] == 'Term Life'\n",
        "hi_2 = ~compliance['Type'].str.contains('Term Life')\n",
        "hi_3 = compliance['Type'] != ''\n",
        "\n",
        "compliance.loc[hi_1 & hi_2 & hi_3, 'Compliance BSC (Y/N)'] = 'No'\n",
        "\n",
        "\n",
        "#inserting new columns\n",
        "#compliance.insert(loc=21, column='Rider Remarks', value='')\n",
        "import re\n",
        "\n",
        "compliance.loc[compliance['Plan Type'].str.contains('Commercial|Dread Diseases/Critical Illness|Eldershield|Hospital & Surgical|Medishield', flags=re.IGNORECASE, regex = True),'Compliance BSC (Y/N)'] = 'No (A&H)'\n",
        "\n",
        "compliance.loc[compliance['Plan Type'].str.contains('LTC'),'Compliance BSC (Y/N)'] = 'No (CIS)'\n",
        "\n",
        "compliance.loc[compliance['Accredited Investor'].str.contains('Yes'),'Compliance BSC (Y/N)'] = 'No (Al)'\n",
        "\n",
        "compliance.loc[compliance['Subject To BSC'].str.contains('Corporate') | compliance['Contact Name'].str.contains('pte|ltd', flags=re.IGNORECASE, regex = True) | compliance['Plan Name'].str.contains('HSBC', flags=re.IGNORECASE, regex = True),'Compliance BSC (Y/N)'] = 'No (Others)'\n",
        "\n",
        "compliance.loc[compliance['Subject To BSC'] == '', 'Compliance BSC (Y/N)'] = 'No'\n",
        "\n",
        "compliance.loc[compliance['Subject To BSC'].str.contains('A&H'),'Compliance BSC (Y/N)'] = 'No (A&H)'\n",
        "\n",
        "hi_4 = compliance['Subject To BSC'] == ''\n",
        "\n",
        "compliance.loc[hi_1 & hi_4,'Compliance BSC (Y/N)'] = 'Yes'\n",
        "\n",
        "# create new columns with blank value in order to match the Ins file\n",
        "#renaming columns to match Ins file\n",
        "column_1 = ['Advisor',\"All E-mail Addresses\",'Created On',\"Contact Name\",\"Contact ID#\",\"All E-mail Addresses.1\",\"Complete Address\",\"Unformatted Postal code\",\"DOB\",\"Age\",\"Nationality\",\"Job Title\",\"Annualized Premium with Rider\",\"Carrier Name\",\"Policy #\",\"Plan Name\",\"Plan Type\",\"Effective Date\",\"Status\",\"Status Date\",\"Subject To BSC\", \"Compliance BSC (Y/N)\",\"IPP Advisory Group\",\"All Advisors\",\"Modified On\",\"Case Modified On\",\"Accrediated Investor\"]\n",
        "\n",
        "compliance = compliance.reindex(column_1, axis = 'columns')\n",
        "\n",
        "\n",
        "#Filter old advisor information\n",
        "aacond = 'Old -'\n",
        "check1 = (compliance['All Advisors'].str.contains(aacond)) & (compliance['Compliance BSC (Y/N)'] == 'Yes')\n",
        "oldadvisordf = compliance[check1]\n",
        "#oldadvisordf.to_excel(oldadvisor_file)\n",
        "\n",
        "#Filter all Compliance BSC Yes information\n",
        "condition1 = compliance['Compliance BSC (Y/N)'].str.contains('Yes')\n",
        "compliance = compliance[condition1]\n",
        "\n",
        "##to manage investment data\n",
        "#calculate age\n",
        "now = pd.Timestamp('now')\n",
        "cis[\"Client's DOB\"] = pd.to_datetime(cis[\"Client's DOB\"], format = '%Y-%m-%d')\n",
        "cis[\"Client's DOB\"].head()\n",
        "cis[\"Client's DOB\"] = cis[\"Client's DOB\"].where(cis[\"Client's DOB\"] < now, cis[\"Client's DOB\"] -  np.timedelta64(100, 'Y'))\n",
        "cis['Age'] = (now - cis[\"Client's DOB\"]).astype('<m8[Y]')\n",
        "\n",
        "#to extract digit only for lump sum amount\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_number(val: str):\n",
        "    if not isinstance(val, str):\n",
        "        return val\n",
        "    regex = r\"\\D*(\\d+)\\D*\"\n",
        "    match = re.match(regex, val)\n",
        "    return match.group(1)\n",
        "\n",
        "cis['Lump Sum'] = cis['Lump Sum'].apply(extract_number)\n",
        "cis['Lump Sum'] = pd.to_numeric(cis['Lump Sum'])\n",
        "\n",
        "#replace RSP NaN to 0\n",
        "index_rsp = cis.loc[cis['RSP'].isna(),'RSP'].index\n",
        "cis.loc[cis['RSP'].isna(),'RSP'] = 0\n",
        "cis.loc[cis['Lump Sum'].isna(), 'Lump Sum'] = 0\n",
        "\n",
        "#create a new column converting frequency to number\n",
        "cis['No Frequency (RSP ONLY)'] = cis['Frequency (RSP ONLY)'].apply(lambda x: 2 if x == 'Semi-annually' else (4 if x == 'Quarterly' else (12 if x == 'Monthly' else 0)))\n",
        "\n",
        "#create RSP total using the new column value above\n",
        "cis['RSP Total'] = cis['No Frequency (RSP ONLY)'] * cis['RSP']\n",
        "\n",
        "#sum RSP and lump sum in a new column 'Annualized Premium with Rider'\n",
        "cis['Annualized Premium with Rider'] = cis['Lump Sum'] + cis['RSP Total']\n",
        "#cis['Annualized Premium with Rider'] = cis.loc[:,['Lump Sum','RSP Total']].sum(axis=1)\n",
        "\n",
        "#create 'Final BSC (Y/N)' column\n",
        "cis['Final BSC (Y/N)'] = cis['Remarks'].apply(lambda x: 'Yes (FAR own trade)' if x == 'FAR own case' else ('No Al' if x == 'Al' else 'Yes'))\n",
        "\n",
        "#overwrite 'Final BSC (Y/N)' value to 'Yes (FAR own trade)' for both same email address and both same name\n",
        "cis.loc[(cis[\"Advisor's email address\"] == cis[\"Client's Email Add\"]),'Final BSC (Y/N)'] = 'Yes (FAR own trade)'\n",
        "cis.loc[(cis[\"Advisor\"] == cis[\"Client's Name\"]),'Final BSC (Y/N)'] = 'Yes (FAR own trade)'\n",
        "\n",
        "#new columns 'Effective Date' & 'Status Date' same as 'Submission Date'\n",
        "cis['Effective Date'] = cis['Submission Date']\n",
        "cis['Status Date'] = cis['Submission Date']\n",
        "\n",
        "# create new columns with blank value in order to match the Ins file\n",
        "#renaming columns to match Ins file\n",
        "cis.rename(columns = {'Transaction Type':'Plan Type'}, inplace = True)\n",
        "column_1 = ['Advisor',\"Advisor's email address\",'Submission Date',\"Client's Name\",\"Client's NRIC\",\"Client's Email Add\",\"Complete Address\",\"Unformatted Postal code\",\"Client's DOB\",\"Age\",\"Nationality\",\"Job Title\",\"Annualized Premium with Rider\",\"Carrier\",\"Policy No.\",\"Plan Name\",\"Plan Type\",\"Effective Date\",\"Mode\",\"Status Date\",\"Subject To BSC\",\"Final BSC (Y/N)\",\"IPP Advisory Group\",\"All Advisors\",\"Modified On\",\"Case Modified On\",\"Accrediated Investor\"]\n",
        "#column_1 = ['Advisor']\n",
        "cis = cis.reindex(column_1, axis = 'columns')\n",
        "\n",
        "condition1 = cis['Final BSC (Y/N)'].str.contains('Yes')\n",
        "cis = cis[condition1]\n",
        "\n",
        "\n",
        "compliance.columns = cis.columns\n",
        "\n",
        "#pd.concat([compliance,cis],ignore_index = False)\n",
        "combined = pd.concat([compliance,cis],ignore_index = False, keys = ['Ins', 'Cis'], names = ['From where?'])\n",
        "combined = combined.reset_index().drop(columns = 'level_1')\n",
        "combined\n",
        "\n",
        "\n",
        "#to check for similar name then group them as the same\n",
        "\n",
        "for i, name in enumerate(combined['Advisor']):\n",
        "    for _, lookup in enumerate(combined['Advisor']):\n",
        "        if name in lookup: \n",
        "            combined['Advisor'][i] = lookup\n",
        "            \n",
        "            \n",
        "#calculate the total number of policy for each advisor\n",
        "\n",
        "combined['Total No Policy'] = ''\n",
        "\n",
        "for i, name in combined['Advisor'].iteritems():\n",
        "    combined_test1 = combined[combined['Advisor'] == name]\n",
        "    combined['Total No Policy'][i] = len(combined_test1)\n",
        "    \n",
        "combined['Round 1 Audit'] = combined['Total No Policy'].apply(lambda x: max(1,round(x*0.05)))\n",
        "combined['Round 2 Audit'] = combined['Total No Policy'].apply(lambda x: max(1,round(x*0.1)) if x > 1 else 0)\n",
        "combined['Round 3 Audit'] = combined['Total No Policy'].apply(lambda x: max(1,round(x*0.2)) if x > 2 else 0)\n",
        "\n",
        "\n",
        "#option 1: find the median number for each advisor then match against their cumulative count to extract the dataframe\n",
        "\n",
        "import math\n",
        "\n",
        "combined['Median'] = ''\n",
        "\n",
        "for i, name in combined['Advisor'].iteritems():\n",
        "    combined_test1 = combined[combined['Advisor'] == name]\n",
        "    combined_test1_median_index = math.floor((len(combined_test1)+1)/2)\n",
        "    combined['Median'][i] = combined_test1_median_index\n",
        "    #median_test1 = combined_test1.iloc[combined_test1_median_index]\n",
        "\n",
        "combined['Cumulative'] = combined.groupby('Advisor').cumcount() + 1\n",
        "\n",
        "\n",
        "#option 2: find the median number for each advisor then match against their cumulative count to extract the dataframe\n",
        "#round 1\n",
        "\n",
        "median_row_all = []\n",
        "result = []\n",
        "\n",
        "for _, v in enumerate(combined['Advisor'].unique()):\n",
        "    temp_df = combined[combined['Advisor'] == v]\n",
        "    temp_df.reset_index(inplace = True)\n",
        "    median_index = temp_df.at[0,'Median']\n",
        "    round_no = temp_df.at[0,'Round 1 Audit']\n",
        "\n",
        "    for j in range(round_no):\n",
        "        median_row = median_index - 1 + j\n",
        "        median_row_all.append(temp_df.iloc[[median_row]])\n",
        "#    median_row_all.append(median_row)\n",
        "#median_row = temp_df.iloc[[18,19]]\n",
        "median_row_all = pd.concat(median_row_all)\n",
        "\n",
        "#round 2\n",
        "median_row_all_r2 = []\n",
        "result = []\n",
        "\n",
        "for _, v in enumerate(combined['Advisor'].unique()):\n",
        "    temp_df = combined[combined['Advisor'] == v]\n",
        "    temp_df.reset_index(inplace = True)\n",
        "    median_index = temp_df.at[0,'Median']\n",
        "    previous_round = temp_df.at[0,'Round 1 Audit']\n",
        "    round_no = temp_df.at[0,'Round 2 Audit']\n",
        "    \n",
        "    for j in range(round_no):\n",
        "        median_row = median_index + previous_round - 1 + j\n",
        "        median_row_all_r2.append(temp_df.iloc[[median_row]])\n",
        "#    median_row_all.append(median_row)\n",
        "#median_row = temp_df.iloc[[18,19]]\n",
        "median_row_all_r2 = pd.concat(median_row_all_r2)\n",
        "\n",
        "#round 3\n",
        "median_row_all_r3 = []\n",
        "result = []\n",
        "\n",
        "for _, v in enumerate(combined['Advisor'].unique()):\n",
        "    temp_df = combined[combined['Advisor'] == v]\n",
        "    temp_df.reset_index(inplace = True)\n",
        "    median_index = temp_df.at[0,'Median']\n",
        "    previous_round = temp_df.at[0,'Round 1 Audit'] + temp_df.at[0,'Round 2 Audit']\n",
        "    round_no = temp_df.at[0,'Round 3 Audit']\n",
        "    \n",
        "    for j in range(round_no):\n",
        "        median_row = median_index - 2 - j\n",
        "        median_row_all_r3.append(temp_df.iloc[[median_row]])\n",
        "#    median_row_all.append(median_row)\n",
        "#median_row = temp_df.iloc[[18,19]]\n",
        "median_row_all_r3 = pd.concat(median_row_all_r3)\n",
        "\n",
        "\n",
        "#to check for similar name then group them as the same\n",
        "\n",
        "for i, name in enumerate(combined['Advisor']):\n",
        "    for _, lookup in enumerate(combined['Advisor']):\n",
        "        if name in lookup: \n",
        "            combined['Advisor'][i] = lookup\n",
        "\n",
        "\n",
        "#create a new dataframe for audit number purpose\n",
        "advisor_count = combined.loc[:, 'Advisor'].value_counts()\n",
        "\n",
        "advisor_count = advisor_count.to_frame()\n",
        "\n",
        "advisor_count.rename(columns = {'Advisor': 'Total Number of Policy'}, inplace = True)\n",
        "advisor_count['Round 1 Audit'] = advisor_count['Total Number of Policy'].apply(lambda x: max(1,round(x*0.05)))\n",
        "advisor_count['Round 2 Audit'] = advisor_count['Total Number of Policy'].apply(lambda x: max(1,round(x*0.1)) if x > 1 else 0)\n",
        "advisor_count['Round 3 Audit'] = advisor_count['Total Number of Policy'].apply(lambda x: max(1,round(x*0.2)) if x > 2 else 0)\n",
        "\n",
        "\n",
        "#create a new dataframe for Advisory group\n",
        "\n",
        "#to check for similar name then group them as the same\n",
        "\n",
        "for i, name in enumerate(combined['IPP Advisory Group']):\n",
        "    for _, lookup in enumerate(combined['IPP Advisory Group']):\n",
        "        if name.casefold() in lookup.casefold(): \n",
        "            combined['IPP Advisory Group'][i] = lookup\n",
        "\n",
        "\n",
        "advisory_group = combined.loc[:, 'IPP Advisory Group'].value_counts()\n",
        "\n",
        "advisory_group = advisory_group.to_frame()\n",
        "\n",
        "advisory_group.rename(columns = {'IPP Advisory Group': 'Total Number of Cases'}, inplace = True)\n",
        "advisory_group['Round 1 Total Number of Cases'] = median_row_all.loc[:, 'IPP Advisory Group'].value_counts()\n",
        "advisory_group['Round 2 Total Number of Cases'] = median_row_all_r2.loc[:, 'IPP Advisory Group'].value_counts()\n",
        "advisory_group['Round 3 Total Number of Cases'] = median_row_all_r3.loc[:, 'IPP Advisory Group'].value_counts()\n",
        "\n",
        "\n",
        "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
        "writer = pd.ExcelWriter('test11.xlsx', engine='xlsxwriter')\n",
        "\n",
        "# Write each dataframe to a different worksheet.\n",
        "combined.to_excel(writer, sheet_name = 'Ins + Cis (Y)')\n",
        "median_row_all.to_excel(writer, sheet_name = 'Round 1 Audit')\n",
        "median_row_all_r2.to_excel(writer, sheet_name = 'Round 2 Audit')\n",
        "median_row_all_r3.to_excel(writer, sheet_name = 'Round 3 Audit')\n",
        "advisor_count.to_excel(writer, sheet_name = 'Advisor Counts')\n",
        "advisory_group.to_excel(writer, sheet_name = 'Advisory Group Counts')\n",
        "\n",
        "\n",
        "# Close the Pandas Excel writer and output the Excel file.\n",
        "writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}